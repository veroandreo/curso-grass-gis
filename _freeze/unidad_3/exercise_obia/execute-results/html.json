{
  "hash": "4b3d4716dac006191e11f3b7eda58035",
  "result": {
    "markdown": "---\ntitle: 'Ejercicio: OBIA en GRASS GIS'\nauthor: Verónica Andreo\ndate: today\nformat:\n  html:\n    code-tools: true\n    code-copy: true\n    code-fold: false\nexecute:\n  eval: false\n  cache: false\n  keep-ipynb: true\n---\n\n## Ejercicio: Clasificación supervisada basada en objetos con datos SPOT\n\n\n### Contenidos\n\n- Mejoramiento del contraste (ecualización del histograma)\n- Calcular índices espectrales y texturas de GLCM\n- Segmentación manual (ensayo y error)\n- Segmentación con USPO\n- Cómputo de las estadísticas de los segmentos\n- Colecta y etiquetado de datos de entrenamiento y validación\n- Clasificación supervisada por Machine Learning\n- Validación\n\n\n### Datos para el ejercicio\n\n- [SPOT 6](https://earth.esa.int/web/eoportal/satellite-missions/s/spot-6-7)\n- VIS - NIR (6 m)\n- PAN (1.5 m)\n- Datos corregidos y fusionados\n\n![](../assets/img/obia_region.png)\n\nDescargar los datos SPOT desde el [aula virtual](https://aulavirtual.ig.conae.unc.edu.ar/mod/page/view.php?id=11082) y mover a la carpeta *`$HOME/gisdata`*\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# paths\ngrassdata='/home/veroandreo/grassdata/'\nlocation=''\nmapset=''\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport os\nimport subprocess\nimport sys\n\n# Ask GRASS GIS where its Python packages are to be able to start it from the notebook\nsys.path.append(\n    subprocess.check_output([\"grass\", \"--config\", \"python_path\"], text=True).strip()\n)\n\n# Importar los paquetes python de GRASS\nimport grass.script as gs\nimport grass.jupyter as gj\n\n# Iniciar GRASS\nsession = gj.init(grassdata, location, mapset)\n```\n:::\n\n\n> **Tareas**\n> \n> - Crear un mapset *`obia_spot`* en el location `posgar2007_4_cba` e importar la imagen SPOT desde la GUI forzando la resolución a 1.5m\n> - Alinear la región a la extensión y resolución de alguna de las bandas importadas \n> - Mostrar la combinación RGB color natural (1: azul, 2: verde, 3: rojo, 4: NIR)\n> - Hacer una ecualización de histograma para mejorar el contraste de visualización\n\n### Importar datos y visualizar\n\nCrear mapset\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# create mapset\ng.mapset -c mapset=obia_spot\n```\n:::\n\n\nImportar bandas multi-espectrales\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n# import pansharpened SPOT data\nr.import input=$HOME/gisdata/SPOT_20180621_PANSHARP_p.tif \\\n  output=SPOT_20180621_PANSHARP \\\n  resolution=value \\\n  resolution_value=1.5\n```\n:::\n\n\nImportar banda pancromática\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n# import SPOT PAN band\nr.import input=$HOME/gisdata/SPOT_20180621_PAN.tif \\\n  output=SPOT_20180621_PAN \\\n  resolution=value \\\n  resolution_value=1.5\n```\n:::\n\n\nAlinear región y guardar la configuración\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n# align region to one of the raster bands\ng.region -p raster=SPOT_20180621_PANSHARP.1 \\\n  save=obia_full\n```\n:::\n\n\nEstablecer *grey* como paleta de colores para bandas RGB\n\n::: {.cell execution_count=7}\n``` {.python .cell-code}\n# set grey color table to RGB bands\nr.colors \\\n  map=SPOT_20180621_PANSHARP.1,SPOT_20180621_PANSHARP.2,SPOT_20180621_PANSHARP.3 \\\n  color=grey\n```\n:::\n\n\nMostrar composición RGB\n\n::: {.cell execution_count=8}\n``` {.python .cell-code}\n# display RGB\nd.mon wx0\nd.rgb red=SPOT_20180621_PANSHARP.3 \\\n  green=SPOT_20180621_PANSHARP.2 \\\n  blue=SPOT_20180621_PANSHARP.1\n```\n:::\n\n\nEcualización de colores\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n# enhance contrast\ni.colors.enhance red=SPOT_20180621_PANSHARP.3 \\\n  green=SPOT_20180621_PANSHARP.2 \\\n  blue=SPOT_20180621_PANSHARP.1 \\\n  strength=95\n```\n:::\n\n\nComposición RGB 321 color natural - SPOT 6)\n\n### Hay valores nulos?\n\nValores nulos en una banda\n\n::: {.cell execution_count=10}\n``` {.python .cell-code}\n# one band\nr.univar map=SPOT_20180621_PANSHARP.2\n```\n:::\n\n\nValores nulos en varias bandas\n\n::: {.cell execution_count=11}\n``` {.python .cell-code}\n# joint stats for all the bands\nr.univar \\\n  map=SPOT_20180621_PANSHARP.1,SPOT_20180621_PANSHARP.2,SPOT_20180621_PANSHARP.3,SPOT_20180621_PANSHARP.4\n```\n:::\n\n\nSi hubiera valores nulos, se deben rellenar antes de comenzar @fa[exclamation-triangle text-orange]\n\n\n### Índices espectrales y texturas GLCM\n\nEstimar NDVI\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n# estimate vegetation index\ni.vi \\\n  output=SPOT_20180621_NDVI \\\n  viname=ndvi \\\n  red=SPOT_20180621_PANSHARP.3 \\\n  nir=SPOT_20180621_PANSHARP.4\n```\n:::\n\n\nInstalar extensión *i.wi* y estimar NDWI\n\n::: {.cell execution_count=13}\n``` {.python .cell-code}\n# install i.wi\ng.extension i.wi\n\n# estimate water index\ni.wi \\\n  output=SPOT_20180621_NDWI \\\n  winame=ndwi_mf \\\n  green=SPOT_20180621_PANSHARP.2 \\\n  nir=SPOT_20180621_PANSHARP.4\n```\n:::\n\n\nEstablecer la paleta de colores *ndwi*\n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n# set ndwi color palette\nr.colors map=SPOT_20180621_NDWI color=ndwi\n```\n:::\n\n\nEstimar medidas de textura: IDM y ASM\n\n::: {.cell execution_count=15}\n``` {.python .cell-code}\n# estimate textures measures\nr.texture \\\n  input=SPOT_20180621_PAN \\\n  output=SPOT_20180621 \\\n  size=7 \\\n  distance=3 \\\n  method=idm,asm\n```\n:::\n\n\nEstablecer paleta *grey* para bandas de textura\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n# set color table to grey for texture bands\nr.colors -e map=SPOT_20180621_IDM color=grey\nr.colors -e map=SPOT_20180621_ASM color=grey\n```\n:::\n\n\nVisualizar\n\nÍndices espectrales y texturas GLCM a partir de bandas SPOT\n\n![](../assets/img/obia_frames.png)\n\n> Sobre qué banda calculamos las texturas?\n\nSi no contamos con una banda pancromática, podemos crearla promediando las bandas visibles\n\n\n```{bash}\n# create pan-vis from RGB (if no pan available)\nR=SPOT_20180621_PANSHARP.3\nG=SPOT_20180621_PANSHARP.2\nB=SPOT_20180621_PANSHARP.1\n\nr.mapcalc \\\n  expression=\"PANVIS = round(($R + $G + $B) / 3)\"\n```\n\n \n### Segmentación\n#### Búsqueda de umbrales de sub y sobre-segmentación\n\nCrear grupo con las bandas únicamente\n\n::: {.cell execution_count=17}\n``` {.python .cell-code}\n# create imagery group (only bands)\ni.group group=spot_bands \\\n  input=SPOT_20180621_PANSHARP.1,SPOT_20180621_PANSHARP.2,SPOT_20180621_PANSHARP.3,SPOT_20180621_PANSHARP.4\n```\n:::\n\n\nDefinir una región más pequeña y salvarla\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n# set smaller region\ng.region -p \\\n  n=6525171 s=6523179 \\\n  w=4390557 e=4393257 \\\n  save=obia_subset\n```\n:::\n\n\nEjecutar una segmentación con umbral pequeño\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n# run segmentation - small threshold\ni.segment \\\n  group=spot_bands \\\n  output=segment_001\\\n  threshold=0.01 \\\n  memory=2000\n# convert output to vector\nr.to.vect -tv input=segment_001 \\\n  output=segment_001 \\\n  type=area\n```\n:::\n\n\nEjecutar una segmentación con umbral más grande\n\n::: {.cell execution_count=20}\n``` {.python .cell-code}\n# run segmentation - larger threshold\ni.segment \\\n  group=spot_bands \\\n  output=segment_005 \\\n  threshold=0.05 \\\n  memory=2000\n# convert output to vector\nr.to.vect -tv \\\n  input=segment_005 \\\n  output=segment_005 \\\n  type=area\n```\n:::\n\n\nSobre-segmentado\n\n![](../assets/img/over_segmented.png)\n\nSub-segmentado\n\n![](../assets/img/sub_segmented.png)\n\n> **Tarea**\n>\n> Se animan a probar con otros valores y en otras regiones?\n\n\n### Segmentación\n#### Búsqueda automática de umbrales por optimización\n\n[i.segment.uspo](https://grass.osgeo.org/grass7/manuals/addons/i.segment.uspo.html)\n\n- Altamente intensivo para un área grande y muchas combinaciones de parámetros\n    - Limitar el tamaño de la región computacional\n    - Limitar el rango de los parámetros\n    - Crear **superpixels** para usarlos como semillas\n    - Cortar la imagen en *tiles* ([i.cutlines](https://grass.osgeo.org/grass-stable/manuals/addons/i.cutlines.html)) y paralelizar la USPO\n\n#### Generación de semillas\n\n[i.superpixels.slic](https://grass.osgeo.org/grass-stable/manuals/addons/i.superpixels.slic.html)\n\n- También puede utilizarse para la segmentación real\n- Muy rápido para reagrupar pequeñas cantidades de píxeles similares\n- Usar para reducir el número de píxeles en un factor de 4-5 y acelerar *i.segment.uspo*\n- Baja compactación para mantener la separación espectral\n\n\n### USPO con superpixels como semillas\n\nInstalar la extensión\n\n::: {.cell execution_count=21}\n``` {.python .cell-code}\n# install i.superpixels.slic\ng.extension i.superpixels.slic\n```\n:::\n\n\nEjecutar *i.superpixels.slic* con bajo valor de compactación\n\n::: {.cell execution_count=22}\n``` {.python .cell-code}\n# run superpixel segm to use as seeds\ni.superpixels.slic \\\n  input=spot_bands \\\n  output=superpixels \\\n  step=2 \\\n  compactness=0.7 \\\n  memory=2000\n```\n:::\n\n\nRGB y resultado de la ejecución de *i.superpixels.slic*\n\n![](../assets/img/superpixels.png)\n\n> Cuántas semillas se generaron? Qué factor de reducción se consigue en comparación a usar todos los pixeles?\n\nDar una mirada a [r.info](https://grass.osgeo.org/grass-stable/manuals/r.info.html) y [g.region](https://grass.osgeo.org/grass-stable/manuals/g.region.html)\n\n\n### USPO con superpixels como semillas\n\nInstalar las extensiones\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n# install extensions\ng.extension r.neighborhoodmatrix\ng.extension i.segment.uspo\n```\n:::\n\n\nEjecutar la segmentación con optimización\n\n::: {.cell execution_count=24}\n``` {.python .cell-code}\n# run segmentation with uspo\ni.segment.uspo group=spot_bands \\\n  output=uspo_parameters.csv \\\n  region=obia_subset \\\n  seeds=superpixels \\\n  segment_map=segs \\\n  threshold_start=0.005 \\\n  threshold_stop=0.05 \\\n  threshold_step=0.005 \\\n  minsizes=3 number_best=5 \\\n  memory=2000 processes=4\n```\n:::\n\n\nConvertir el \"mejor\" resultado a vector\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n# convert to vector the rank1\nr.to.vect -tv \\\n  input=segs_obia_subset_rank1 \\\n  output=segs \\\n  type=area\n```\n:::\n\n\nZoom al resultado de ejecutar la segmentación con USPO\n\n![](../assets/img/result_uspo.png)\n\n> Cuántos segmentos obtuvieron?\n\nDar una mirada a [v.info](https://grass.osgeo.org/grass-stable/manuals/v.info.html)\n\n\n### Estadísticas: [i.segment.stats](https://grass.osgeo.org/grass-stable/manuals/addons/i.segment.stats.html)\n\n\nInstalar las extensiones\n\n::: {.cell execution_count=26}\n``` {.python .cell-code}\n# install extensions\ng.extension i.segment.stats\ng.extension r.object.geometry\n```\n:::\n\n\nEjecutar *i.segment.stats*\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n# extract stats for segments\ni.segment.stats \\\n  map=segs_obia_subset_rank1 \\\n  rasters=SPOT_20180621_ASM,SPOT_20180621_IDM,SPOT_20180621_NDVI,SPOT_20180621_NDWI,SPOT_20180621_PAN \\\n  raster_statistics=mean,stddev \\\n  area_measures=area,perimeter,compact_circle,compact_square \\\n  vectormap=segs_stats \\\n  processes=4\n```\n:::\n\n\nTabla de atributos con las estadísticas estimadas para cada objeto\n\n![](../assets/img/segs_stats_attr_table.png)\n\n### Datos de entrenamiento\n\nInfo básica de los puntos de entrenamiento provistos\n\n::: {.cell execution_count=28}\n``` {.python .cell-code}\n# get info of labeled points\nv.info labeled_points\n```\n:::\n\n\nCopiarse el vector al mapset `obia_spot`\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n# copy vector to current mapset (access to tables from different mapsets is not allowed)\ng.copy vector=labeled_points@PERMANENT,labeled_points\n```\n:::\n\n\nCuántos puntos de cada clase tenemos?\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\n# get number of points per class\ndb.select \\\n  sql=\"SELECT train_class,COUNT(cat) as count_class\n       FROM labeled_points\n       GROUP BY train_class\"\n```\n:::\n\n\nSeleccionar segmentos sobre los cuales tenemos puntos de entrenamiento\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n# select segments that are below labeled points\nv.select \\\n  ainput=segs_stats \\\n  binput=labeled_points \\\n  output=train_segments \\\n  operator=overlap\n```\n:::\n\n\nCuántos segmentos contienen puntos de entrenamiento?\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\n# get info of segments\nv.info train_segments\n```\n:::\n\n\nSelección de segmentos con puntos de entrenamiento\n\n![](../assets/img/points_in_segments.png)\n\n\n### Datos de entrenamiento\n\nAgregar columna al vector con los segmentos para luego transferir la clase\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n# add column to train segments\nv.db.addcolumn train_segments \\\n  column=\"class int\"\n```\n:::\n\n\nAsignar la clase de los puntos a los segmentos\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n# assign label from points to segments\nv.distance from=train_segments \\\n  to=labeled_points \\\n  upload=to_attr \\\n  column=class \\\n  to_column=train_class\n```\n:::\n\n\nCuántos segmentos de cada clase tenemos?\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\n# group training segments per class\ndb.select \\\n  sql=\"SELECT class,COUNT(cat) as count_class\n       FROM train_segments\n       GROUP BY class\"\n```\n:::\n\n\n#### Datos de entrenamiento\n\n![](../assets/img/assign_color_to_train_segments.png)\n\nAsignación de colores interactivamente\n\n- Ir agregando valores\n- Seleccionar colores \n- Previsualizar\n- Guardar la paleta creada como *obia_urban* para reusar posteriormente\n\n\nSelección y etiquetado de datos de entrenamiento y validación\n\n- Ejecutar una clasificación no supervisada con 10 clases\n- Extraer una *x* cantidad de puntos por clase ([r.sample.category](https://grass.osgeo.org/grass-stable/manuals/addons/r.sample.category.html))\n- Etiquetar los puntos manualmente\n- Usar puntos para transferir las etiquetas a los segmentos como ya vimos\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\n# Unsupervised classification\ni.group group=spot_all \\\n  input=SPOT_20180621_ASM,SPOT_20180621_IDM,SPOT_20180621_NDVI,SPOT_20180621_NDWI,SPOT_20180621_PAN,SPOT_20180621_PANSHARP.1,SPOT_20180621_PANSHARP.2,SPOT_20180621_PANSHARP.3,SPOT_20180621_PANSHARP.4\ni.cluster group=spot_all signaturefile=sig classes=10\ni.maxlik group=spot_all signaturefile=sig output=uns_clas\n\n# install extension\ng.extension r.sample.category\n\n# get n points per class\nr.sample.category input=uns_clas \\\n  output=uns_clas_points \\\n  npoints=150\n\n# Manually label points\n```\n:::\n\n\n### Clasificación con Machine learning\n\nInstalar la extensión\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n# install extension\ng.extension v.class.mlR\n```\n:::\n\n\nEjecutar la clasificación\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\n# run classification\nv.class.mlR -nf \\\n  segments_map=segs_stats \\\n  training_map=train_segments \\\n  train_class_column=class \\\n  output_class_column=class_rf \\\n  classified_map=classification \\\n  raster_segments_map=segs_obia_subset_rank1 \\\n  classifier=rf \\\n  folds=5 partitions=10 tunelength=10 \\\n  weighting_modes=smv \\\n  weighting_metric=accuracy \\\n  output_model_file=model \\\n  variable_importance_file=var_imp.txt \\\n  accuracy_file=accuracy.csv \\\n  classification_results=all_results.csv \\\n  model_details=classifier_runs.txt \\\n  r_script_file=Rscript_mlR.R \\\n  processes=4\n```\n:::\n\n\nEstablecer paleta de colores\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\n# set color table that we created interactively\nr.colors \\\n  map=classification_rf \\\n  rules=obia_urban\n```\n:::\n\n\nResultado de la clasificación supervisada con Machine Learning basada en objetos\n\n> El proceso de clasificación usualmente conlleva una serie de iteraciones que implican selección de variables más importantes, búsqueda de más/mejores datos de entrenamiento y validación\n\n\n### Validación\n\n- Se usan datos independientes para validar las clasificaciones\n- Se construye una **matriz de confusión** que permite visualizar los errores por clase en los elementos que están fuera de la diagonal\n- Se estiman varias medidas relacionadas a la precisión, ej.: **overall accuracy** y **kappa**\n\n\n### Validación\n\nDistintas opciones:\n1. Generar un nuevo set de puntos y etiquetarlos\n2. Separar el set de puntos etiquetados en *train* y *test* de antemano\n\n\n#### Validación en GRASS GIS\n\n[r.kappa](https://grass.osgeo.org/grass-stable/manuals/r.kappa.html)\n\n- Necesita mapas raster como *input*\n  - Transformar los segmentos de validación a formato raster usando la columna *`class`* como fuente de valores para los pixeles\n\n\n> Tarea \n>\n> Generar un set de validación de al menos 50 segmentos y ejecutar [**r.kappa**](https://grass.osgeo.org/grass-stable/manuals/r.kappa.html)\n\n\n#### Validación en GRASS GIS\n\nUna vez creado el vector de segmentos con etiquetas *testing*, convertirlo a formato raster\n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\n# convert labeled test segments to raster\nv.to.rast map=testing \\\n  use=attr \\\n  attribute_column=class \\\n  output=testing\n```\n:::\n\n\nEjecutar *r.kappa*\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\n# create confusion matrix and estimate precision measures\nr.kappa \\\n  classification=classification_rf \\\n  reference=testing\n```\n:::\n\n\nAlternativamente, podemos separar el set de puntos etiquetados en *train* y *test*. Vamos a R.\n\nCargar librerías\n\n```{r}\n# load libraries\nlibrary(rgrass7)\nlibrary(dplyr)\n```\n\n\nLeer el vector desde GRASS\n\n```{r}\n# load vector from GRASS\nv <- read_VECT(\"labeled_points\")\n```\n\n\nCrear set de validación\n\n```{r}\n# test dataset\ntest <- v %>%\n        group_by(train_class) %>%\n        sample_frac(.3)\n\ntable(test$train_class)\n```\n\n\nSeparar set de entrenamiento\n\n```{r}\n# training dataset\ntrain <- v[!v$cat %in% test$cat,]\n```\n\n\nEscribir los vectores a GRASS nuevamente\n\n```{r}\n# write back into GRASS\nwrite_VECT(test, \"test\")\nwrite_VECT(train, \"train\")\n```\n\n\n\n> **Tarea**\n>\n> Ejecutar nuevamente la clasificación usando sólo el vector *train*\n\n\nAgregar columna al vector *test*\n\n::: {.cell execution_count=42}\n``` {.python .cell-code}\n# add column to test point map\nv.db.addcolumn map=test \\\n  column=\"pred_class integer\"\n```\n:::\n\n\nObtener las clases predichas para los segmentos de validación\n\n::: {.cell execution_count=43}\n``` {.python .cell-code}\n# query the classified map\nv.what.rast map=test \\\n  column=pred_class \\\n  raster=classification_rf\n```\n:::\n\n\n#### Validación en R\n\nLeer el vector test que tiene la clase predicha\n\n```{r}\n# read the test vector\ntest_complete <- readVECT(\"test\")\n```\n\n\nCargar la librería *caret* y obtener la matriz de confusión\n\n```{r}\n# confusion matrix and evaluation stats\nlibrary(caret)\nrf_CM <- confusionMatrix(as.factor(test_complete$pred_class),\n                         as.factor(test_complete$train_class))\nprint(rf_CM)\n```\n\n\n\n> **Tarea**\n>\n> - Explorar el módulo [v.kcv](https://grass.osgeo.org/grass-stable/manuals/v.kcv.html)\n> - Cómo se podría haber utilizado para separar los puntos etiquetados en training y test?\n> - Cuál es la diferencia entre dicho módulo y la separación que realizamos en R?\n\nDar una mirada a [v.divide.training_validation](https://github.com/mundialis/v.divide.training_validation)\n\n\n\n**Gracias por su atención!!**\n\n![GRASS GIS logo](assets/img/grass_logo_alphab.png)\n\n",
    "supporting": [
      "exercise_obia_files"
    ],
    "filters": [],
    "includes": {}
  }
}