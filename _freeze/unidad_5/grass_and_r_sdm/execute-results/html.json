{
  "hash": "79c8abcf57c7d7955f1e9d72de3d2eb9",
  "result": {
    "markdown": "---\ntitle: 'R y GRASS: Modelado de nicho'\nauthor: Verónica Andreo\ndate: '`r Sys.Date()`'\nformat:\n  html:\n    code-tools: true\n    code-copy: true\n    code-fold: false\nexecute:\n  eval: false\n  cache: false\n  keep-ipynb: true\n---\n\n<!-- # ```{r setup, include = FALSE} -->\n<!-- # knitr::opts_chunk$set(eval = FALSE) -->\n<!-- # # knitr::opts_chunk$set(cache = TRUE) -->\n<!-- # ``` -->\n\nEn esta última sesión, vamos a demostrar y ejemplificar el uso combinado de \nGRASS y R para modelar la distribución de *Aedes aegypti* en la provincia \nde Córdoba en función de variables ambientales. Algunas de estas variables\nprovienen de los ejercicios realizados en la unidad de series de tiempo y \notras serán generadas durante este ejercicio.\n\nAntes de empezar y para ganar tiempo, conectemos nuestro drive e instalemos \nGRASS y los paquetes de R que vamos a usar en esta sesión.\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\n# import drive from google colab\nfrom google.colab import drive\n# define mounting point for drive\ndmp = \"/content/drive\"\n# mount drive\ndrive.mount(dmp)\n```\n:::\n\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\n%%bash\nDEBIAN_FRONTEND=noninteractive \nsudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable \napt update \napt install grass subversion grass-dev\napt remove libproj22\n```\n:::\n\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n!grass --config path\n```\n:::\n\n\nInstalamos y cargamos al entorno el paquete de python que nos permite hacer\ninterfaz con R dentro de una Jupyter notebook.\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\n!pip install rpy2==3.5.1\n%reload_ext rpy2.ipython\n```\n:::\n\n\nChequeamos nuestra sesión de R.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\n%R sessionInfo()\n```\n:::\n\n\nInstalamos todos los paquetes necesarios para este ejercicio. \n*This might take a while...*\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\n%%R\ninstall.packages(\"rgrass\")\ninstall.packages(\"terra\")\ninstall.packages(\"raster\")\ninstall.packages(\"sf\")\ninstall.packages(\"biomod2\")\ninstall.packages(\"dismo\")\ninstall.packages(\"usdm\")\ninstall.packages(\"SDMtune\")\ninstall.packages(\"zeallot\")\ninstall.packages(\"rJava\")\ninstall.packages(\"ggpubr\")\ninstall.packages(\"tmap\")\ninstall.packages(\"tmaptools\")\n```\n:::\n\n\n# [**rgrass**](https://cran.r-project.org/web/packages/rgrass/index.html)\n\nEl paquete de R que hace las veces de interfaz entre R y GRASS GIS se\ndenomina `rgrass`. Este paquete ha sido desarrollado y sigue siendo mantenido\npor @rgrass y se puede encontrar en: \n<https://github.com/rsbivand/rgrass/>. \n\n:::{.callout-note}\nPueden ver la viñeta del paquete para más explicaciones, algo de contexto y \nejemplos: <https://rsbivand.github.io/rgrass/>.\n:::\n\nLas principales funciones que podemos encontrar en el paquete `rgrass` son las \nsiguientes:\n\n- `initGRASS()`: inicia una sesión de GRASS GIS desde R, similar a \n`gs.setup.init()` o `gj.init()`.\n- `execGRASS()`: ejecuta comandos de GRASS, similar a `gs.run_command()` \n- `gmeta()`: muestra los metadatos de localización de GRASS.\n- `read_VECT()` y `read_RAST()`: leen mapas vectoriales y raster desde la base \nde datos de GRASS a objetos `SpatVect` y `SpatRast` del paquete *terra* de R.\n- `write_VECT()` y `write_RAST()`: escriben objetos del paquete *terra* en la \nbase de datos de GRASS GIS.\n\n::: {.callout-note}\nEl paquete `terra` es desarrollado y mantenido por @terra y eventualmente \nreemplazará a `raster`. Detalles sobre el paquete *terra* pueden encontrarse en:\n<https://rspatial.github.io/terra/reference/terra-package.html> y <https://rspatial.org/spatial/index.html>.\n:::\n\n\n## Cómo usamos `rgrass`?\n\nGRASS GIS y R se pueden utilizar juntos de dos maneras:\n\nA. Usar [R dentro de una sesión de GRASS GIS](https://grasswiki.osgeo.org/wiki/R_statistics/rgrass#R_within_GRASS),\nes decir, iniciar R (o RStudio) desde una sesión de GRASS\n\n- escribimos `R` o `rstudio &` en la terminal GRASS GIS o en la pestaña \n*Consola* de la interfaz gráfica\n- una vez en R (o RStudio) cargamos el paquete `rgrass` (previo haberlo instalado)\n- usamos `read_VECT()`, `read_RAST()` para leer datos de GRASS en R\n- accedemos a los módulos y la base de datos de GRASS GIS a través de `execGRASS()` \n- escribimos datos resultantes en la base de datos de GRASS con `write_VECT()` y \n`write_RAST()`\n\n\n![](../assets/img/grass_terminal_calling_R.png){width=\"60%\" fig-align=\"center\"}\n\n::::columns\n:::{.column width=\"60%\"}\n![](../assets/img/open_rstudio_from_grass_gui.png)\n:::\n\n:::{.column width=\"40%\"}\n![](../assets/img/open_rstudio_from_grass_gui_b.png)\n:::\n::::\n\nB. Iniciar y usar [GRASS GIS dentro de una sesión de R](https://grasswiki.osgeo.org/wiki/R_statistics/rgrass#GRASS_within_R), es \ndecir, nos conectamos a la base de datos de GRASS GIS desde R (o RStudio).\n\n- Primero cargamos el paquete `rgrass`\n- Necesitamos iniciar GRASS GIS con `initGRASS()` desde R y para ello,\nnecesitamos especificar el ejecutable de GRASS y las ubicaciones de la base \nde datos, el proyecto (location) y mapset\n- Accedemos a los módulos GRASS GIS a través de `execGRASS()`\n- usamos `read_VECT()`, `read_RAST()`, `write_VECT()` y `write_RAST()` para \nleer datos desde y hacia la base de datos GRASS.\n\n![](../assets/img/grass_within_rstudio_session.png){width=\"70%\" fig-align=\"center\"}\n\n::: {.callout-note}\nOriginalmente, `rgrass` estaba destinado a aplicar funciones de GRASS en \ndatos fuera de la base de datos de GRASS; de ahí que algunos prefieran \ncrear proyectos (i.e., *locations*) desechables o temporarios. Por ejemplo:\n\n\n```{r}\nlibrary(terra)\n\nf <- system.file(\"ex/elev.tif\", package=\"terra\")\nr <- rast(f)\n\nlibrary(rgrass)\ninitGRASS(home=tempdir(), SG=r, override=TRUE)\n```\n\n:::\n\n# SDM - modelado de la distribución de especies\n\nEl flujo de trabajo comúnmente utilizado para el modelado de la distribución de \nespecies (*SDM por su sigla en Inglés*) consiste en la recopilación de sitios de \nocurrencia de la especie o evento de interés (ej., casos de una enfermedad, \nfocos de fuego, ietc.), así como de variables ambientales que puedan ser \nrelevantes para explicar su distribución.\nLos datos de ocurrencia y las variables predictoras son las entradas de algún  \nalgoritmo determinado o modelo (ej., GLM, Random Forest, MaxEnt, etc.). Una vez\nestamos \"contentos\" con el ajuste del modelo, el próximo paso es la predicción. \nEn este caso, hablamos de prediccón ambiental cuando nos interesa explicar e \ninterpretar la relación entre las variables y la probabilidad de ocurrencia \n(curvas de respuesta) y predicción geográfica cuando nos interesa ver plasmadas\nen el espacio geografico el resultado de esas relaciones (mapas).\n\n![](../assets/img/workflow_sdm_other.png){width=85% fig-align=\"center\"}\n\nExisten varios paquetes para realizar SDM. En este caso usaremos\n[SDMtune](https://cloud.r-project.org/web/packages/SDMtune/index.html)\ndesarrollado y mantenido por @sdmtune. Este paquete proporciona funciones \nque cubren todo el flujo de trabajo de SDM, desde la preparación de datos\nhasta la selección de variables, la optimización y evaluación de los modelos.\nEchen un vistazo a los artículos en el sitio web del paquete para obtener\nmás detalles y tutoriales: \n<https://consbiol-unibern.github.io/SDMtune/index.html>.\n\n# Manos a la obra\n\n## Cargamos los paquetes de R\n\n::: {#load_libraries .cell execution_count=7}\n``` {.python .cell-code}\n%%R\nlibrary(rgrass)\nlibrary(sf)\nlibrary(terra)\nlibrary(biomod2)\nlibrary(dismo)\nlibrary(usdm)\nlibrary(SDMtune)\nlibrary(zeallot)\nlibrary(tmap)\nlibrary(tmaptools)\n```\n:::\n\n\n## Iniciamos GRASS\n\nUsaremos la **opción B**, es decir, iniciamos GRASS GIS desde R en un proyecto y\nmapset existentes. Notar las similitudes con `gj.init()` de `grass.jupyter`\ny `gs.setup.init()` de `grass.script`.\n\n::: {#grass_init .cell results='hide' execution_count=8}\n``` {.python .cell-code}\n%%R\n# path to GRASS binaries (run `grass --config path`)\ngrassbin <- system(\"grass --config path\", intern = TRUE)\n# path to GRASS database in GDrive\ngrassdata <- \"/content/drive/MyDrive/curso_grass_2023/grassdata\"\n# path to project\nproject <- \"posgar2007_4_cba\"\n# path to mapset\nmapset <- \"PERMANENT\"\n\n# start GRASS GIS from R\ninitGRASS(gisBase = grassbin, \n          gisDbase = grassdata, \n          location = project, \n          mapset = mapset, \n          override = TRUE,\n          remove_GISRC= TRUE)\n```\n:::\n\n\nExploramos los mapas raster y vectoriales disponibles en el mapset PERMANENT:\n\n::: {.cell execution_count=9}\n``` {.python .cell-code}\n%%R\nr <- execGRASS(\"g.list\", \n               parameters = list(type = \"raster\",\n                                 mapset = \".\"))\nv <- execGRASS(\"g.list\", \n               parameters = list(type = \"vector\",\n                                 mapset = \".\"))\n```\n:::\n\n\n## Datos de presencia/ocurrencia\n\nPara este ejercicio vamos a generar los puntos de ocurrencia del mosquito \n*Aedes aegypti* como un sub-conjunto al azar de las localidades (áreas \nedificadas) de la provincia de Córdoba que estén a una altura de menos \nde 850 m. Notar que estamos trabajando en la base de datos de GRASS GIS, pero\ndesde R.\n\n::: {#create_presences .cell results='hide' execution_count=10}\n``` {.python .cell-code}\n%%R\n# Extract centroids from built-up area polygons\nexecGRASS(\"v.extract\", \n          parameters = list(input=\"area_edificada_cba\", \n                            type=\"centroid\", \n                            output=\"area_edificada_cba_centroides\", \n                            random=250))\n\n# convert centroids to points\nexecGRASS(\"v.type\", \n          parameters = list(input=\"area_edificada_cba_centroides\", \n                            output=\"area_edificada_cba_puntos\", \n                            from_type=\"centroid\", \n                            to_type=\"point\"))\n\n# extract elevation data for points\nexecGRASS(\"v.what.rast\", \n          parameters = list(map=\"area_edificada_cba_puntos\", \n                            raster=\"elevation\", \n                            column=\"elevation\"))\n\n# filter points by elevation, keep those <= 850m\nexecGRASS(\"v.extract\",\n          parameters = list(input=\"area_edificada_cba_puntos\",\n                            where=\"elevation <= 850\",\n                            output=\"aedes_aegypti\"))\n```\n:::\n\n\nAhora leemos desde GRASS los datos de ocurrencia que generamos, los convertimos \nen un objeto `sf`, y los graficamos.\n\n::: {#read_vectors .cell results='hide' execution_count=11}\n``` {.python .cell-code}\n%%R\n# Read vector layers\npresence <- st_as_sf(read_VECT(\"aedes_aegypti\"))\n```\n:::\n\n\n::: {.cell execution_count=12}\n``` {.python .cell-code}\n%%R\n# Display presence vector\nplot(presence)\n```\n:::\n\n\nPodemos usar la función `plot()` para visualizar la geometría o la \ngeometría y los atributos (o una selección de los mismos) de los objetos `sf`.\n\n::: {#plot_with_sf .cell execution_count=13}\n``` {.python .cell-code}\n%%R\n# Plot only the geometry \nplot(st_geometry(presence))\n\n# Plot geometry + attr\nplot(presence[\"elevation\"])\n```\n:::\n\n\n## Datos de background\n\nEl algoritmo MaxEnt que vamos a usar en este ejercicio, requiere contrastar\nlas variables ambientales en los sitios de ocurrencia con el resto del ambiente\ndisponible para la especie, el *background*. Entonces, necesitamos generar \npuntos de background para caracterizar este ambiente disponible.\n\nUna opción es generar puntos al azar sobre nuestra área de estudio. No obstante,\nno es cierto que toda la extensión del área de estudio está disponible para \n*Aedes aegypti*. Esta especie de mosquito no cría en aguas abiertas y tampoco \nsobre las salinas. Entonces, vamos a enmascarar primero esas áreas del ambiente\ndisponible. \n\n::: {.cell execution_count=14}\n``` {.python .cell-code}\n%%R\n# Check region\ngmeta()\n```\n:::\n\n\n::: {#create_mask_bg .cell execution_count=15}\n``` {.python .cell-code}\n%%R\n# Generar máscara a partir del raster de LULC\nexpression <- \n  \"no_water = if(landcover_2018 == 7 || landcover_2018 == 8, null(), landcover_2018)\"\n\nexecGRASS(\"r.mapcalc\",\n          parameters = list(expression=expression))\n```\n:::\n\n\nLuego, leemos a R la máscara creada para visualizarla\n\n::: {.cell execution_count=16}\n``` {.python .cell-code}\n%%R\n# Import mask\nno_water <- raster(read_RAST(\"no_water\"))\nplot(no_water)\n```\n:::\n\n\nComo la región tiene una resolución de 30 m, vamos a llevarla a 1 km, para\nasegurarnos una mejor separación de los puntos de background, y volvemos a\nleer la máscara dentro de R. \n\n::: {#create_bg_points .cell execution_count=17}\n``` {.python .cell-code}\n%%R\n# Change resolution\nexecGRASS(\"g.region\",\n          parameters = list(res=\"1000\"),\n          flags = c(\"a\",\"p\"))\n\n# Upscale\nexecGRASS(\"r.resamp.stats\",\n          parameters = list(input=\"no_water\",\n                            output=\"MASK\",\n                            method=\"mode\"))\n\n# Leer en R la mascara_spp que vive en GRASS\nmask <- raster(read_RAST(\"MASK\"))\n```\n:::\n\n\nAhora sí, generamos los puntos de background utilizando una función del paquete\n`dismo`[@dismo] y los convertimos a `sf` para luego visualizarlos.\n\n::: {.cell execution_count=18}\n``` {.python .cell-code}\n%%R\n# Generate random points within mask\nset.seed(123)\nbackground <- randomPoints(mask = mask, \n                           n = 500)\n\n# Convert to sf to plot\nbackground_sf <- st_as_sf(as.data.frame(background), \n                          coords = c(1,2), \n                          crs = st_crs(mask))\n```\n:::\n\n\n:::{.callout-caution title=\"Pregunta\"}\nCon qué funcion de GRASS podríamos haber hecho algo similar?\n:::\n\nVisualizamos el mapa que usamos como máscara junto con los vectores de\npresencia y background usando la librería `tmap` [@tmap].\n\n::: {.cell execution_count=19}\n``` {.python .cell-code}\n%%R\n# Aux data\nbbox <- st_bbox(mask)\n\nfig_puntos <- \n  tm_shape(mask, \n           bbox = bbox) +\n  tm_raster(title = \"Classes\") +\n  tm_shape(presence) +\n  tm_dots(size = 0.02) +\n  tm_layout(main.title = \"Aedes aegypti\",\n            main.title.fontface = \"italic\",\n            main.title.size = 0.7,\n            main.title.position = \"left\",\n            legend.show = TRUE,\n            legend.outside = TRUE)\n\ntmap_save(fig_puntos, \n          filename = \"fig_puntos_y_mascara.png\", \n          width = 1000, height = 1300)\n```\n:::\n\n\n![Mapa generado con tmap](fig_puntos_y_mascara.png){width=60%}\n\n## Variables ambientales \n\nAntes de leer las variables ambientales que obtuvimos a partir de las series de\ntiempo de LST y NDVI, vamos a generar dos mapas ráster que representan la \ndistancia a fuentes de agua y rutas y caminos, respectivamente. Para eso, \nvamos a usar mapas ya disponibles en el mapset PERMANENT. \n\n::: {#create_rasters_water .cell execution_count=20}\n``` {.python .cell-code}\n%%R\n# Patch water lines + water bodies\nexecGRASS(\"v.patch\",\n          parameters = list(input=\"lineas_aguas_continentales_perennes_cba,\n                            areas_aguas_continentales_perennes_cba,\n                            embalses\",\n                            output=\"lineas_y_cuerpos_de_agua_cba\"))\n\n# Convert to raster\nexecGRASS(\"v.to.rast\",\n          parameters = list(input=\"lineas_y_cuerpos_de_agua_cba\",\n                            output=\"lineas_y_cuerpos_de_agua_cba\",\n                            use=\"val\"))\n\n# Distance to water and roads\nexecGRASS(\"r.grow.distance\",\n          parameters = list(input=\"lineas_y_cuerpos_de_agua_cba\",\n                            distance=\"distancia_agua\"))\n```\n:::\n\n\n::: {#create_rasters_roads .cell execution_count=21}\n``` {.python .cell-code}\n%%R\n# Patch primary + secondary roads\nexecGRASS(\"v.patch\",\n          parameters = list(input=\"vial_primaria_cba,vial_secundaria_cba\",\n                            output=\"red_vial_cba\"))\n# Convert to raster\nexecGRASS(\"v.to.rast\",\n          parameters = list(input=\"red_vial_cba\",\n                            output=\"red_vial_cba\",\n                            use=\"val\"))\n\n# Distance to roads\nexecGRASS(\"r.grow.distance\",\n          parameters = list(input=\"red_vial_cba\",\n                            distance=\"distancia_caminos\"))\n```\n:::\n\n\nLeemos los mapas generados y los visualizamos con `plot()`, que en este caso\nreconoce los objetos `SpatRast`.\n\n::: {#read_distance_maps .cell execution_count=22}\n``` {.python .cell-code}\n%%R\n\ndistancia_agua <- read_RAST(\"distancia_agua\")\ndistancia_caminos <- read_RAST(\"distancia_caminos\")\n\nplot(c(distancia_agua,distancia_caminos), \n     main=c(\"Distancia agua\", \"Distancia rutas\"))\n```\n:::\n\n\nTambién podemos usar `tmap` y su función `tm_facets()`\n\n::: {.cell execution_count=23}\n``` {.python .cell-code}\n%%R\ndistancia <- read_RAST(c(\"distancia_agua\",\"distancia_caminos\"))\n\nfig_raster_facet <- \n  tm_shape(distancia, \n           bbox = bbox) +\n  tm_raster(style = \"cont\",\n            palette = \"magma\",\n            legend.show = FALSE) +\n  tm_facets()\n\nfig_raster_facet\n```\n:::\n\n\n### Lectura de datos ráster de otros mapsets\n\nPara leer mapas de otros mapsets, necesitamos agregar esos mapsets a la lista de \nmapsets accesibles en el mapset donde estamos ahora.\n\n::: {#add_mapsets .cell execution_count=24}\n``` {.python .cell-code}\n%%R\nexecGRASS(\"g.mapsets\",\n          parameters = list(mapset=\"modis_lst\",\n                            operation=\"add\"))\nexecGRASS(\"g.mapsets\",\n          parameters = list(mapset=\"modis_ndvi\",\n                            operation=\"add\"))\nexecGRASS(\"g.mapsets\",\n          flags = \"p\")\n```\n:::\n\n\nLeemos ahora algunas de las variables que derivamos de las series temporales de\nLST y NDVI. Primero, necesitamos aplicar la máscara de los límites de la \nprovincia.\n\n::: {.cell execution_count=25}\n``` {.python .cell-code}\n%R execGRASS(\"r.mask\", parameters = list(vector=\"provincia_cba\"))\n```\n:::\n\n\n::: {#read_rasters .cell results='hide' execution_count=26}\n``` {.python .cell-code}\n%%R\n# List rasters to import\nto_import <- c(\"LST_Day_minimum\",\n               \"LST_Day_maximum\",\n               \"LST_Day_average\",\n               \"ndvi_maximum\",\n               \"ndvi_minimum\")\n\n# Read raster layers\npredictors <- list()\nfor (i in to_import){ \n  predictors[i] <- read_RAST(i) }\n```\n:::\n\n\nAgrupamos todos los rasters de variables ambientales.\n\n::: {.cell execution_count=27}\n``` {.python .cell-code}\n%%R\n# Stack rasters\npredictors_r <- rast(c(predictors,distancia))\ncapas <- c(\"LST_Day_minimum\", \n           \"LST_Day_maximum\", \n           \"LST_Day_average\",\n           \"ndvi_maximum\",\n           \"ndvi_minimum\", \n           \"distancia_agua\",\n           \"distancia_caminos\")\nnames(predictors_r) <- capas\n```\n:::\n\n\n## Preparación de los datos\n\nAhora que hemos creado y/o importado los registros de presencia, los puntos de\nbackground y las variables predictivas, necesitamos preparar los datos en un \nformato llamado *samples with data* (SWD). Éste es básicamente una tabla con \ncoordenadas de presencia y background más los valores correspondientes a las \nvariables predictoras para cada punto.\n\n::: {#data_prep1 .cell execution_count=28}\n``` {.python .cell-code}\n%%R\n# Variables for models\nsp <- \"Aedes aegypti\"\npresence_coords <- st_coordinates(presence)\nbackground_coords <- background\nenv <- predictors_r\n\n# Prepare data: SWD\ndata_sp <- prepareSWD(species = sp, \n                      p = presence_coords, \n                      a = background_coords, \n                      env = env)\n\ndata_sp\n```\n:::\n\n\n## Definición de parámetros\n\nAquí definimos algunos de los valores de entrada necesarios para el flujo de \ntrabajo:\n\n::: {.cell execution_count=29}\n``` {.python .cell-code}\n%%R\nseed=123\nperc_test = 0.2\nk = 4\nmethod=\"Maxent\"\ncor_th=0.7\nperm=10\nimp_th=10\n```\n:::\n\n\n## Datos de entrenamiento y evaluación\n\nEntrenaremos el modelo con un 80% de muestras de presencia, y dejaremos el 20% \nrestante para la evaluación al final.\n\n::: {.cell execution_count=30}\n``` {.python .cell-code}\n%%R\n# Create training and test sets\nc(train_sp, test_sp) %<-% \n  trainValTest(data_sp, \n               test = perc_test,\n               only_presence = TRUE, \n               seed = seed)\n```\n:::\n\n\n::: {.cell execution_count=31}\n``` {.python .cell-code}\n%R train_sp\n```\n:::\n\n\n::: {.cell execution_count=32}\n``` {.python .cell-code}\n%R test_sp\n```\n:::\n\n\n## Creación de *folds* para validación cruzada\n\nComo usaremos validación cruzada durante el entrenamiento del modelo, creamos \nlos *folds* con anticipación. En este caso utilizamos *folds* aleatorios, \npero existen otros métodos de determinarlos. Como estamos limitados por la \ncantidad de registros de presencia, crearemos solo 4 *folds* o *subconjuntos*.\nEl algoritmo utilizará iterativamente 3 subconjuntos para entrenar y 1 para \nvalidar, pero siempre dentro del entrenamiento.\n\n::: {.cell execution_count=33}\n``` {.python .cell-code}\n%%R\n# Create folds \nran_folds <- randomFolds(train_sp, \n                         k = k,\n                         only_presence = TRUE, \n                         seed = seed)\n```\n:::\n\n\n## Entrenamiento con validación cruzada\n\nPrimero entrenaremos un llamado *modelo completo*, es decir, un modelo con todos\nlos predictores, y de allí eliminaremos aquellos que estén altamente \ncorrelacionados y cuya contribución a la predicción no sea importante.\n\n::: {.cell execution_count=34}\n``` {.python .cell-code}\n%%R\n# Train a full model\nfull_model_sp <- train(method = method,\n                       data = train_sp, \n                       folds = ran_folds)\n\nfull_model_sp\n```\n:::\n\n\nVeamos las predicciones geográficas del modelo completo o *full model*\n\n::: {.cell execution_count=35}\n``` {.python .cell-code}\n%%R\npred_full_model <- predict(full_model_sp,\n                           data = env,\n                           type = \"cloglog\")\n\nplot(pred_full_model)\n```\n:::\n\n\n## Selección de variables\n\n### Remover variables altamente correlacionadas \n\nLuego procedemos a eliminar los predictores correlacionados ya que proporcionan\ninformación altamente redundante y pueden afectar el rendimiento de los modelos,\nes decir, como con todos los modelos, queremos que sea simple y del mayor \nrendimiento posible. Usaremos el área bajo la curva ROC (AUC) como métrica de \nrendimiento y eliminaremos las variables correlacionadas solo si el AUC disminuye\nsi las mantenemos.\n\n::: {.cell execution_count=36}\n``` {.python .cell-code}\n%%R\n# Prepare background locations to test correlation\nbg_sp <- prepareSWD(species = sp, \n                    a = background_coords,\n                    env = env)\n\n# Remove variables with correlation higher than 0.7 \n# while accounting for the AUC\nvs_sp <- varSel(full_model_sp,\n                metric = \"auc\", \n                bg4cor = bg_sp, \n                cor_th = cor_th,\n                permut = perm,\n                interactive = FALSE)\n```\n:::\n\n\nExploremos el objeto de salida\n\n::: {.cell execution_count=37}\n``` {.python .cell-code}\n%R vs_sp@data\n```\n:::\n\n\n### Remover variables de menor importancia\n\nDespués de descartar las variables correlacionadas, también eliminaremos las \nvariables que tengan una contribución porcentual o una importancia inferior al \n10%, considerando como su mantenimiento o remoción afecta al AUC.\n\n::: {.cell execution_count=38}\n``` {.python .cell-code}\n%%R\n# remove less important variables only if auc does not decrease\nreduc_var_sp <- reduceVar(vs_sp,\n                          th = imp_th, \n                          metric = \"auc\", \n                          test = TRUE, \n                          permut = perm, \n                          use_jk = TRUE,\n                          interactive = FALSE)\n```\n:::\n\n\nExploremos el objeto resultante\n\n::: {.cell execution_count=39}\n``` {.python .cell-code}\n%R reduc_var_sp\n```\n:::\n\n\nAhora necesitamos recrear el objeto SWD y los conjuntos de datos de entrenamiento \ny evaluación, pero solo con las variables seleccionadas, para poder ejecutar el \nmodelo final y hacer predicciones.\n\n::: {.cell execution_count=40}\n``` {.python .cell-code}\n%%R\n# Get only relevant variables from the reduced model\nretained_varnames <- names(reduc_var_sp@models[[1]]@data@data)\n\n# Subset stack\nenv <- terra::subset(env, retained_varnames)\n\n# SWD with the selected vars\nsubset_train_sp <- prepareSWD(species = sp, \n                              p = presence_coords,\n                              a = background_coords,\n                              env = env)\n\nc(train_sp, test_sp) %<-% \n  trainValTest(subset_train_sp, \n               test = perc_test, \n               only_presence = TRUE, \n               seed = seed)\n```\n:::\n\n\n## Predicciones con el modelo seleccionado\n\nAhora entrenamos el modelo final con el conjunto de entrenamiento completo, \nya no necesitamos los *folds* en este punto. Tengan en cuenta que también \nutilizamos las *feature classes* (fc) y la regularización (reg) del mejor \nmodelo obtenido anteriormente. En este caso, son solo valores predeterminados,\npero si también realizamos una optimización de hiperparámetros, pueden diferir.\n\n::: {.cell execution_count=41}\n``` {.python .cell-code}\n%%R\nfinal_model_sp <- train(method = method, \n                        data = train_sp,\n                        fc = reduc_var_sp@models[[1]]@model@fc,\n                        reg = reduc_var_sp@models[[1]]@model@reg)\n```\n:::\n\n\n:::{.callout-note}\nSi les interesa conocer opciones de optimización de hiperparámetros en el \ncontexto de los SDM, puedes chequear el siguiente artículo:\n<https://consbiol-unibern.github.io/SDMtune/articles/tune-hyperparameters.html>\n:::\n\nHagamos las predicciones en el espacio geográfico y exploremos el resultado\n\n::: {.cell execution_count=42}\n``` {.python .cell-code}\n%%R\nmap_sp_maxent <- predict(final_model_sp,\n                         data = env, \n                         type = \"cloglog\")\n\nplot(map_sp_maxent)\n```\n:::\n\n\n## Guardamos la predicción en GRASS \n\nAhora podemos escribir el ráster con las predicciones del modelo final en la \nbase de datos de GRASS.\n\n::: {.cell execution_count=43}\n``` {.python .cell-code}\n%%R\nwrite_RAST(map_sp_maxent, \n           \"Aedes_aegypti_maxent\", \n           flags = c(\"o\",\"overwrite\"))\n```\n:::\n\n\nCorroboramos que el mapa creado esté allí\n\n::: {.cell execution_count=44}\n``` {.python .cell-code}\n%%R\nexecGRASS(\"g.list\", \n          parameters = list(type=\"raster\",\n                            pattern=\"Aedes*\"))\n```\n:::\n\n\n## Evaluación del modelo\n\nQueremos saber qué tan bueno es nuestro modelo, por eso en este paso usamos \nel conjunto de datos de evaluación que separamos al principio. \nUn AUC de 0,5 significaría que el modelo funciona equivalentemente a lanzar una\nmoneda al aire.\nAUC es lo que llamamos una métrica de evaluación independiente de umbral.\n\n::: {.cell execution_count=45}\n``` {.python .cell-code}\n%%R\n# AUC\nauc_maxent <- auc(final_model_sp, test = test_sp)\nauc_maxent\n```\n:::\n\n\nNormalmente el resultado del SDM se convierte en mapas de presencia/ausencia. \nPara determinar qué umbral utilizar, realizamos evaluaciones dependientes del \numbral.\n\n::: {.cell execution_count=46}\n``` {.python .cell-code}\n%%R\n# Threshold dependent evaluation\nth_maxent <- thresholds(final_model_sp, \n                        type = \"cloglog\", \n                        test = test_sp)\n\nknitr::kable(th_maxent, format = 'html', digits = 2)\n```\n:::\n\n\nElegimos un umbral y creamos un mapa binario, i.e., de presencia y ausencia\n\n::: {.cell execution_count=47}\n``` {.python .cell-code}\n%%R\np = map_sp_maxent >= 0.5\na = map_sp_maxent < 0.5\nmap_sp_maxent[p] <- 1\nmap_sp_maxent[a] <- 0\n\nplot(map_sp_maxent)\n```\n:::\n\n\n## Importancia de las variables\n\nLa importancia de las variables es un indicador de la contribución variable \na la predicción.\n\n::: {.cell execution_count=48}\n``` {.python .cell-code}\n%%R\nvi_model_sp <- maxentVarImp(final_model_sp)\nvi_model_sp\n```\n:::\n\n\n::: {.cell execution_count=49}\n``` {.python .cell-code}\n%R plotVarImp(vi_model_sp)\n```\n:::\n\n\n## Curvas de respuesta\n\nLas curvas de respuesta nos dan una idea de la relación entre las variables \npredictoras y la probabilidad de ocurrencia del evento de interés.\n\n::: {.cell execution_count=50}\n``` {.python .cell-code}\n%%R\nmy_rp <- function(i){\n  plotResponse(reduc_var_sp, i)\n}\n\nplotlist <- lapply(retained_varnames, my_rp)\nlabels <- LETTERS[1:length(retained_varnames)]\nggpubr::ggarrange(plotlist = plotlist, labels = labels)\n```\n:::\n\n\nCerramos el mapset y terminamos :)\n\n::: {.cell execution_count=51}\n``` {.python .cell-code}\n%%R\n# close the mapset\nunlink_.gislock()\n```\n:::\n\n\n# Disclaimer\n\nRecordar que éste es sólo un ejemplo sencillo para hacer SDM y sólo el \ncomienzo... Hay:\n\n- otros modelos para probar\n- ajuste/optimización de hiperparámetros\n- ensemble de modelos\n- evaluación de la incertidumbre, i.e., dónde podemos predecir con confianza\n- muchos otros paquetes relevantes:\n   - [*dismo*](https://cran.r-project.org/web/packages/dismo/index.html), [*sdm*](https://cran.r-project.org/web/ paquetes/sdm/index.html), [*kuenm*](https://github.com/marlonecobos/kuenm), [*caret*](https://cran.r-project.org/web/packages/ caret/index.html), [*CAST*](https://cran.r-project.org/web/packages/CAST/index.html), etc.\n\n# Referencias\n\n:::{#refs}\n\n:::\n\n",
    "supporting": [
      "grass_and_r_sdm_files"
    ],
    "filters": [],
    "includes": {}
  }
}